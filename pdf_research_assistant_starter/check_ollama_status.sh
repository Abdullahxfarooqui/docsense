#!/bin/bash
# Quick status check for Ollama integration

echo "===================================="
echo "üîç OLLAMA STATUS CHECK"
echo "===================================="
echo ""

echo "1Ô∏è‚É£ Ollama Service Status:"
if ps aux | grep -v grep | grep "ollama serve" > /dev/null; then
    echo "   ‚úÖ Ollama service is running"
else
    echo "   ‚ùå Ollama service is NOT running"
    echo "   Run: ollama serve &"
fi
echo ""

echo "2Ô∏è‚É£ Model Download Status:"
if ps aux | grep -v grep | grep "ollama pull" > /dev/null; then
    echo "   ‚è≥ Model download in progress..."
    echo "   Please wait a few more minutes"
else
    echo "   ‚úÖ No active downloads"
fi
echo ""

echo "3Ô∏è‚É£ Available Models:"
ollama list
echo ""

echo "4Ô∏è‚É£ Configuration (.env):"
cd /home/farooqui/Desktop/Docsense/pdf_research_assistant_starter
echo "   Base URL: $(grep OPENAI_BASE_URL .env)"
echo "   Model: $(grep OPENAI_MODEL .env | head -1)"
echo ""

echo "5Ô∏è‚É£ Next Steps:"
if ollama list | grep -q "llama3.2:3b"; then
    echo "   ‚úÖ Model ready! You can:"
    echo "   1. Test: ollama run llama3.2:3b 'Hello'"
    echo "   2. Restart app: pkill -f streamlit && streamlit run app.py"
else
    echo "   ‚è≥ Wait for download to complete"
    echo "   Check again in 2-3 minutes with: bash check_ollama_status.sh"
fi
echo ""
echo "===================================="
