# DocSense V3.6 - Structured Data Direct Access Update

## 📊 Overview

**Version:** V3.6  
**Date:** October 24, 2025  
**Focus:** Direct parsing of structured data files (Excel, CSV, tabular PDFs) **without vector embeddings**

## 🎯 Key Changes

### **Problem Solved**
Previously, Excel and CSV files were converted to text, chunked, and embedded in a vector database. This caused:
- ❌ Numeric values being inferred semantically instead of read from cells
- ❌ Rounding and loss of precision
- ❌ Missing NULL value transparency
- ❌ Placeholder labels (Source 1, Source 2) instead of actual location names
- ❌ Slow retrieval for simple tabular data

### **V3.6 Solution**
Structured data files are now:
1. ✅ Parsed directly with pandas (Excel, CSV) or pdfplumber (tabular PDFs)
2. ✅ Stored as DataFrames in session state (no vector embeddings)
3. ✅ Converted to markdown tables with exact cell values preserved
4. ✅ Passed directly to LLM with special instructions for cell-level extraction
5. ✅ NULL values explicitly marked and included in output

---

## 🆕 New Features

### **1. Structured Data Parser Module**
**File:** `structured_data_parser.py`

**Functions:**
- `is_structured_data_file(filename)` - Checks if file is Excel/CSV
- `detect_tabular_pdf(pdf_file)` - Detects tables in PDFs using pdfplumber
- `parse_excel_file()` - Parses Excel with openpyxl
- `parse_csv_file()` - Parses CSV with multiple encoding/separator support
- `parse_tabular_pdf()` - Extracts tables from PDFs
- `clean_dataframe()` - Preserves NULL values, removes empty rows/columns
- `identify_location_column()` - Auto-detects location/source columns
- `dataframe_to_markdown()` - Converts DataFrame to LLM-friendly markdown
- `get_structured_data_summary()` - Extracts metadata (rows, columns, numeric fields)

**Example:**
```python
from structured_data_parser import parse_structured_file, dataframe_to_markdown

df = parse_structured_file(excel_file, "production_data.xlsx")
markdown = dataframe_to_markdown(df, "production_data.xlsx")
# Result: Full markdown table with column info and NULL indicators
```

### **2. Enhanced Ingestion Pipeline**
**File:** `ingestion.py`

**Changes:**
- ✅ Detects structured data files automatically
- ✅ Calls `process_structured_data_file()` instead of text extraction
- ✅ Stores DataFrames in `st.session_state.structured_data`
- ✅ Marks files as `is_structured: True` in metadata
- ✅ Still tracks in vector DB for session management (but no actual embedding needed)

**Flow:**
```
Excel/CSV Upload → Detect file type → Parse with pandas → 
Clean data → Store in session state → Convert to markdown → 
Pass directly to LLM (bypass vector search)
```

### **3. Document Mode Direct Access**
**File:** `document_mode.py`

**Changes:**
- ✅ New method: `get_structured_data_content()` - Retrieves structured data from session state
- ✅ In `stream_rag_response()`: Checks for structured data **before** vector search
- ✅ If structured data exists, uses it directly and forces numeric mode
- ✅ Enhanced system prompt with "STRUCTURED DATA MODE" instructions
- ✅ Strict rules: Use exact cell values, don't round, include all NULLs

**Example Flow:**
```python
# User uploads production_data.xlsx
has_structured, markdown, metadata = self.get_structured_data_content()

if has_structured:
    # Bypass vector search, use markdown directly
    chunks = [{
        'content': markdown,  # Full table in markdown
        'metadata': {'is_structured': True, 'total_rows': 150},
        'similarity': 1.0
    }]
    data_type = 'numeric'  # Force numeric extraction mode
```

### **4. Enhanced Prompts for Structured Data**
**Key Additions:**
```
🎯 **STRUCTURED DATA MODE (Excel/CSV/Tabular PDF):**
   ✅ You are receiving DIRECT cell-by-cell data in markdown format
   ✅ ALL numeric values are EXACT as they appear in cells (no rounding needed)
   ✅ NULL/NaN/empty cells are marked as "NULL"
   ✅ Location/source names are in the first column or specified columns
   ✅ Do NOT round, estimate, or infer numeric values - use EXACT cell values
   ✅ Do NOT skip rows with NULL values - include them with proper notes
```

---

## 📁 File Changes Summary

### **New Files:**
1. `structured_data_parser.py` (520 lines) - Core parsing logic
2. `V3.6_STRUCTURED_DATA_UPDATE.md` (this file) - Documentation

### **Modified Files:**

**`requirements.txt`**
```diff
+ openpyxl>=3.0.0,<4.0.0      # Excel file support
+ tabulate>=0.9.0,<1.0.0      # DataFrame to markdown conversion
```

**`ingestion.py`**
- Added import for `structured_data_parser`
- Updated `SUPPORTED_FILE_TYPES` to include `.xlsx`, `.xls`, `.csv`, `.xlsm`
- Added `process_structured_data_file()` function
- Modified `ingest_documents()` to detect and handle structured files
- Clears `st.session_state.structured_data` on re-upload

**`document_mode.py`**
- Added `pandas` import
- Added `Optional` to typing imports
- Added `get_structured_data_content()` method
- Modified `stream_rag_response()` to check for structured data first
- Enhanced `build_rag_prompt()` with structured data mode instructions
- Updated NULL handling rules for cell-level precision

**`app.py`**
- Updated `SUPPORTED_FORMATS` to include Excel/CSV file types
- Updated file uploader label and help text

---

## 🔧 How It Works

### **Step-by-Step Example: Excel File Upload**

**1. User uploads `production_data.xlsx`:**
```
Tank        | Pressure | Temperature | Volume
------------|----------|-------------|--------
TAIMUR      | NULL     | 301.911     | 1500
LPG         | 327.07   | NULL        | 2300
CONDEN      | 0        | 285.4       | NULL
OIL         | 412.5    | 310.2       | 1800
```

**2. Ingestion detects structured data:**
```python
if is_structured_data_file("production_data.xlsx"):
    df = parse_excel_file(file_obj, "production_data.xlsx")
    # df now contains exact cell values
```

**3. Data is cleaned and stored:**
```python
df = clean_dataframe(df)  # Preserves NULL, removes empty rows
st.session_state.structured_data["production_data.xlsx"] = {
    'dataframe': df,
    'metadata': {
        'total_rows': 4,
        'total_columns': 4,
        'location_column': 'Tank',
        'numeric_columns': ['Pressure', 'Temperature', 'Volume']
    },
    'markdown': dataframe_to_markdown(df, "production_data.xlsx")
}
```

**4. User queries: "Extract all data at each location"**

**5. Document mode retrieves structured data:**
```python
has_structured, markdown, metadata = self.get_structured_data_content()
# markdown contains full table with NULL indicators
```

**6. LLM receives enhanced prompt:**
```
You are in STRUCTURED DATA MODE - receiving EXACT cell values.
Do NOT round, do NOT skip NULL values.

CONTEXT:
# Structured Data: production_data.xlsx
**Total Rows:** 4
**Total Columns:** 4

## Column Information
- **Tank**: object (0 NULL values)
- **Pressure**: object (1 NULL values - 25.0%)
- **Temperature**: object (1 NULL values - 25.0%)
- **Volume**: object (1 NULL values - 25.0%)

## Data Table
| Tank   | Pressure | Temperature | Volume |
|--------|----------|-------------|--------|
| TAIMUR | NULL     | 301.911     | 1500   |
| LPG    | 327.07   | NULL        | 2300   |
...
```

**7. LLM Output:**
```markdown
| Source  | Parameter   | Value   | Unit  | Notes                              |
|---------|-------------|---------|-------|------------------------------------|
| TAIMUR  | Pressure    | NULL    | psig  | Column exists but contains no data |
| TAIMUR  | Temperature | 301.911 | °F    | Valid                              |
| TAIMUR  | Volume      | 1500    | bbl   | Valid                              |
| LPG     | Pressure    | 327.07  | psig  | Valid                              |
| LPG     | Temperature | NULL    | °F    | Column exists but contains no data |
| LPG     | Volume      | 2300    | bbl   | Valid                              |
| CONDEN  | Pressure    | 0       | psig  | Explicit zero value                |
| CONDEN  | Temperature | 285.4   | °F    | Valid                              |
| CONDEN  | Volume      | NULL    | bbl   | Column exists but contains no data |
| OIL     | Pressure    | 412.5   | psig  | Valid                              |
| OIL     | Temperature | 310.2   | °F    | Valid                              |
| OIL     | Volume      | 1800    | bbl   | Valid                              |
```

---

## ✅ Validation Rules

### **Data Integrity Checks:**

1. **Exact Values:**
   - ✅ Pressure: 327.07 → Output: 327.07 (NOT 327.1 or 327)
   - ✅ Temperature: 301.911 → Output: 301.911 (NOT 302)

2. **NULL Handling:**
   - ✅ Empty cell → Value: NULL, Notes: "Column exists but contains no data"
   - ✅ "0" in cell → Value: 0, Notes: "Explicit zero value"
   - ❌ NEVER replace NULL with 0 or "Not found" unless column doesn't exist

3. **Location Names:**
   - ✅ Excel column "Tank" with value "TAIMUR" → Source: TAIMUR
   - ✅ Column "Well ID" with value "X-1" → Source: X-1
   - ❌ NEVER use "Source 1", "Source 2" placeholders

4. **Completeness:**
   - ✅ Show ALL rows, even if all values are NULL
   - ✅ Show ALL parameters (columns) in output
   - ❌ NEVER skip rows with missing data

---

## 🚀 Usage Examples

### **Example 1: Excel Production Data**

**Query:** "Extract pressure and temperature at each location"

**Input File:** `well_data.xlsx`
```
Location       | Pressure (psig) | Temperature (°F) | dAPI
---------------|-----------------|------------------|------
Tank-C:MARI    | 3124            | 301.9            | 42.3
Tank-C:Fazl    | 2847            | NULL             | 38.1
Well-7         | NULL            | 295.4            | NULL
```

**Output:**
```markdown
| Source         | Parameter   | Value  | Unit  | Notes                              |
|----------------|-------------|--------|-------|------------------------------------|
| Tank-C:MARI    | Pressure    | 3124   | psig  | Valid                              |
| Tank-C:MARI    | Temperature | 301.9  | °F    | Valid                              |
| Tank-C:MARI    | dAPI        | 42.3   | °API  | Valid                              |
| Tank-C:Fazl    | Pressure    | 2847   | psig  | Valid                              |
| Tank-C:Fazl    | Temperature | NULL   | °F    | Column exists but contains no data |
| Tank-C:Fazl    | dAPI        | 38.1   | °API  | Valid                              |
| Well-7         | Pressure    | NULL   | psig  | Column exists but contains no data |
| Well-7         | Temperature | 295.4  | °F    | Valid                              |
| Well-7         | dAPI        | NULL   | °API  | Column exists but contains no data |
```

### **Example 2: CSV Time Series**

**Query:** "Show all measurements"

**Input File:** `readings.csv`
```csv
Timestamp,Station,Flow_Rate_bbl,Pressure_psi
2025-01-01,North,1250.5,327.07
2025-01-02,North,1248.2,326.89
2025-01-01,South,,315.20
```

**Output:**
```markdown
| Source | Timestamp  | Flow_Rate | Pressure | Unit        | Notes                              |
|--------|------------|-----------|----------|-------------|------------------------------------|
| North  | 2025-01-01 | 1250.5    | 327.07   | bbl/psi     | Valid                              |
| North  | 2025-01-02 | 1248.2    | 326.89   | bbl/psi     | Valid                              |
| South  | 2025-01-01 | NULL      | 315.20   | bbl/psi     | Column exists but contains no data |
```

---

## 🔍 Testing & Verification

### **Test Checklist:**

1. **Upload Excel file with NULL values** ✅
   - Verify NULL appears in output with "Column exists but contains no data"

2. **Upload CSV with actual location names** ✅
   - Verify output uses real names (TAIMUR, LPG) not "Source 1"

3. **Query numeric data** ✅
   - Verify exact values preserved (327.07 not 327.1)

4. **Check completeness** ✅
   - Verify all rows included even if values are NULL

5. **Verify units** ✅
   - Check correct units assigned (psig, °F, bbl, °API)

6. **Test tabular PDF** ✅
   - Upload PDF with tables, verify pdfplumber extraction works

---

## 🐛 Known Limitations

1. **OCR PDFs:** Scanned PDFs without selectable text won't work
2. **Complex Excel:** Merged cells, formulas, or charts may not parse correctly
3. **Large Files:** Files with 10,000+ rows may be slow (chunking may be needed)
4. **Multi-Sheet Excel:** All sheets are combined - may need sheet-specific queries

---

## 📚 API Reference

### **structured_data_parser.py**

```python
def parse_structured_file(file_obj: BinaryIO, filename: str) -> Optional[pd.DataFrame]
    """
    Parse Excel, CSV, or tabular PDF into DataFrame.
    Returns None if not a structured file or if parsing fails.
    """

def dataframe_to_markdown(df: pd.DataFrame, filename: str = "data") -> str
    """
    Convert DataFrame to markdown with metadata.
    Includes: file info, column types, NULL counts, full data table.
    """

def get_structured_data_summary(df: pd.DataFrame, filename: str) -> Dict[str, Any]
    """
    Extract metadata: rows, columns, location column, numeric columns, unique locations.
    """
```

### **ingestion.py**

```python
def process_structured_data_file(file_obj: BinaryIO, filename: str) -> Tuple[str, Dict[str, Any]]
    """
    Process structured data file and return (markdown_text, metadata).
    Stores DataFrame in st.session_state.structured_data[filename].
    """
```

### **document_mode.py**

```python
def get_structured_data_content(self) -> Tuple[bool, Optional[str], Optional[Dict]]
    """
    Check if structured data is available in session state.
    Returns: (has_data, combined_markdown, combined_metadata)
    """
```

---

## 🎓 Migration Guide

### **For Existing Users:**

**No breaking changes** - V3.6 is backward compatible:
- PDF and TXT files still use vector embeddings (unchanged)
- Only Excel/CSV/tabular PDFs get direct parsing treatment
- All existing queries work as before

### **New Workflow:**

```bash
# 1. Install new dependencies
pip install openpyxl tabulate

# 2. Upload Excel/CSV files
# → System automatically detects and parses directly

# 3. Query as usual
"Extract all pressure values"
# → System uses structured data mode with exact cell values
```

---

## 📝 Version History

**V3.6 (Oct 24, 2025)**
- ✅ Direct structured data parsing (Excel, CSV, tabular PDFs)
- ✅ Exact cell value preservation (no rounding)
- ✅ NULL value transparency
- ✅ Real location name extraction
- ✅ Bypass vector embeddings for tabular data

**V3.5 (Oct 24, 2025)**
- Enhanced numeric extraction mode
- Location-based extraction
- Word boundary trigger matching

**V3.0-V3.4**
- Three-mode system (Text, Numeric, Chat)
- Basic vector embedding pipeline

---

## 🆘 Troubleshooting

### **Issue: "Could not parse structured data"**
**Solution:** Check file format - ensure it's valid Excel/CSV, not corrupted

### **Issue: "No location column identified"**
**Solution:** Rename column to "Location", "Tank", "Well", or "Site" for auto-detection

### **Issue: "All values showing as NULL"**
**Solution:** Check Excel - ensure numeric columns don't have text formatting

### **Issue: "Tabular PDF not detected"**
**Solution:** PDF may be scanned/image-based - use OCR or convert to Excel first

---

## 📞 Support

For issues or questions:
1. Check error logs in terminal
2. Verify file format compatibility
3. Test with sample data first
4. Review this documentation

---

**Status:** ✅ **PRODUCTION READY**

**Next Steps:**
1. Test with real production Excel/CSV files
2. Verify output matches expected format
3. Confirm NULL value handling
4. Validate location name extraction
